#!/usr/bin/env python3
"""
æµ‹è¯•WebRTC Audio Processing Pythonç»‘å®šçš„ç®€å•è„šæœ¬
"""

import numpy as np
import webrtc_apm

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("Testing WebRTC Audio Processing Python bindings...")
    
    # åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨
    processor = webrtc_apm.AudioProcessor()
    print("âœ“ AudioProcessor created successfully")
    
    # å¯ç”¨å„ç§åŠŸèƒ½
    processor.set_echo_cancellation_enabled(True)
    processor.set_noise_suppression_enabled(True)
    processor.set_gain_control_enabled(True)
    print("âœ“ Audio processing features enabled")
    
    # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ•°æ®
    sample_rate = 16000
    duration = 1.0  # 1ç§’
    samples = int(sample_rate * duration)
    
    # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘ï¼šæ­£å¼¦æ³¢ + å™ªå£°
    t = np.linspace(0, duration, samples)
    frequency = 440  # A4éŸ³ç¬¦
    audio_data = np.sin(2 * np.pi * frequency * t).astype(np.float32)
    audio_data += 0.1 * np.random.normal(0, 1, samples).astype(np.float32)
    
    print(f"âœ“ Generated test audio: {samples} samples at {sample_rate}Hz")
    
    # å¤„ç†éŸ³é¢‘
    processed_audio = processor.process_stream(audio_data, sample_rate)
    print(f"âœ“ Audio processed successfully: {len(processed_audio)} samples")
    
    # éªŒè¯è¾“å‡º
    assert len(processed_audio) == len(audio_data), "Output length mismatch"
    assert processed_audio.dtype == np.float32, "Output dtype mismatch"
    
    print("âœ“ All tests passed!")
    
    return True

def test_config_class():
    """æµ‹è¯•é…ç½®ç±»"""
    print("\nTesting Config class...")
    
    config = webrtc_apm.Config()
    
    # é…ç½®å›å£°æ¶ˆé™¤
    config.echo_canceller.enabled = True
    config.echo_canceller.mobile_mode = False
    
    # é…ç½®å™ªå£°æŠ‘åˆ¶
    config.noise_suppressor.enabled = True
    config.noise_suppressor.level = 2
    
    # é…ç½®å¢ç›Šæ§åˆ¶
    config.gain_controller.enabled = True
    config.gain_controller.mode = 1
    
    print("âœ“ Config class works correctly")
    
    return True

def test_multichannel_audio():
    """æµ‹è¯•å¤šå£°é“éŸ³é¢‘"""
    print("\nTesting multichannel audio processing...")
    
    processor = webrtc_apm.AudioProcessor()
    
    # åˆ›å»ºç«‹ä½“å£°æµ‹è¯•æ•°æ®
    sample_rate = 16000
    duration = 0.5
    samples = int(sample_rate * duration)
    channels = 2
    
    # ç”Ÿæˆç«‹ä½“å£°éŸ³é¢‘
    audio_data = np.random.normal(0, 0.1, (samples, channels)).astype(np.float32)
    
    # å¤„ç†ç«‹ä½“å£°éŸ³é¢‘
    processed_audio = processor.process_stream(audio_data, sample_rate, channels)
    
    assert processed_audio.shape == audio_data.shape, "Multichannel shape mismatch"
    print("âœ“ Multichannel audio processing works")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    try:
        print(f"WebRTC Audio Processing Python bindings v{webrtc_apm.__version__}")
        print("=" * 60)
        
        test_basic_functionality()
        test_config_class()
        test_multichannel_audio()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ All tests completed successfully!")
        print("\nExample usage:")
        print("  import webrtc_apm")
        print("  processor = webrtc_apm.AudioProcessor()")
        print("  processor.set_echo_cancellation_enabled(True)")
        print("  processed = processor.process_stream(audio_data, 16000)")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)